{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "sem3_semantics.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9WdrW45cxdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "from gensim.models import Word2Vec, KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE3z2FAscxeI",
        "colab_type": "text"
      },
      "source": [
        "## Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvz78a9GcxeK",
        "colab_type": "text"
      },
      "source": [
        "Реализуйте поиск по [Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian) на нескольких векторных моделях\n",
        "\n",
        "    1. fasttext, модель ruscorpora_none_fasttextskipgram_300_2_2019\n",
        "    2. elmo, модель ruwikiruscorpora_lemmas_elmo_1024_2019\n",
        "    3. bert*, RuBERT - необязательно\n",
        "   \n",
        "Первые две обученные модели можно скачать на сайте [rusvectores](https://rusvectores.org/en/models/).\n",
        "\n",
        "BERT делать необязательно, но если сделаете, 6 за курс у вас автоматом. Модель можно [найти тут](http://docs.deeppavlov.ai/en/master/features/models/bert.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo9MWySah2jD",
        "colab_type": "code",
        "outputId": "81b9a473-a46b-4166-8281-325d0d1a6d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-X418SRa59J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import pymorphy2 as pm\n",
        "import string\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SenLcdPQa08B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(file):\n",
        "  '''Функция из файла делает списки запросов'''\n",
        "  with open(file, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader, None)\n",
        "        documents_1 = []\n",
        "        documents_2 = []\n",
        "        data = []\n",
        "        is_dupl = []\n",
        "        for row in reader:\n",
        "          documents_1.append(row[1])\n",
        "          documents_2.append(row[2])\n",
        "          data.append([int(row[0])])\n",
        "          is_dupl.append(int(row[3]))\n",
        "            \n",
        "  return data, documents_1, documents_2, is_dupl\n",
        "\n",
        "data, documents_1, documents_2, is_dupl= get_data('quora_question_pairs_rus.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IoGAS45hlC-",
        "colab_type": "code",
        "outputId": "0853a414-093c-4e90-8691-47637f0eb770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopWords = list(stopwords.words('russian'))\n",
        "morph = pm.MorphAnalyzer()\n",
        "\n",
        "def preprocess(text : list) -> list:\n",
        "    \"\"\"Функция на вход получает текст и возвращает список нормализованных слов, без знаков пунктуации, без стопслов\"\"\"\n",
        "    text = text.lower()\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    filtered_words = list(filter(lambda token: token not in stopwords.words('russian'), tokens))\n",
        "    norm_words = [morph.parse(token)[0].normal_form for token in filtered_words]\n",
        "    return norm_words"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cndapNqoewyh",
        "colab_type": "text"
      },
      "source": [
        "### FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAON1FKNdxcg",
        "colab_type": "code",
        "outputId": "bf1678f3-cb38-45f9-eb8d-11c1368d2486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "!wget 'http://vectors.nlpl.eu/repository/11/181.zip'\n",
        "!unzip '181.zip' -d 'fasttext'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-08 17:32:06--  http://vectors.nlpl.eu/repository/11/181.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2622716217 (2.4G) [application/zip]\n",
            "Saving to: ‘181.zip’\n",
            "\n",
            "181.zip             100%[===================>]   2.44G  20.6MB/s    in 2m 9s   \n",
            "\n",
            "2019-10-08 17:34:15 (19.4 MB/s) - ‘181.zip’ saved [2622716217/2622716217]\n",
            "\n",
            "Archive:  181.zip\n",
            "  inflating: fasttext/meta.json      \n",
            "  inflating: fasttext/model.model    \n",
            "  inflating: fasttext/model.model.vectors_ngrams.npy  \n",
            "  inflating: fasttext/model.model.vectors.npy  \n",
            "  inflating: fasttext/model.model.vectors_vocab.npy  \n",
            "  inflating: fasttext/README         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC_30g22hDd9",
        "colab_type": "code",
        "outputId": "3c534acf-96e9-49a9-e41e-2f43df0e1964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "f_model = KeyedVectors.load('fasttext/model.model')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2N78ntUkZCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index2doc = dict(enumerate(documents_1))\n",
        "doc2index = {value : key for key, value in index2doc.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJy2Y-zap9KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs_processed = [preprocess(document) for document in documents_1[:100000]]\n",
        "idx2doc_n = dict(enumerate(docs_processed))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c45R7kysjoXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fasttext_matrix(data):  \n",
        "  ft_matrix = []\n",
        "  for document in data:\n",
        "    empty_m = np.zeros((len(document), f_model.vector_size))\n",
        "    for i, element in enumerate(document):\n",
        "      if element in f_model.vocab:\n",
        "        empty_m[i] = f_model.wv[element]\n",
        "    if empty_m.shape[0] != 0:\n",
        "      vector = np.mean(empty_m, axis=0)\n",
        "    ft_matrix.append(vector)\n",
        "  ft_matrix = np.array(ft_matrix)\n",
        "  return ft_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiWTtO7Ckl7S",
        "colab_type": "code",
        "outputId": "611c9e33-d61e-4137-f3cc-28c9c3acb4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "%%time\n",
        "ft_matrix = fasttext_matrix(docs_processed)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.28 s, sys: 328 ms, total: 7.61 s\n",
            "Wall time: 7.63 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqw120DtyPdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cos_sim(v1, v2):\n",
        "    return np.inner(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mECEEmBlxKlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ft_search(query, ft_matrix, model):\n",
        "  query = [preprocess(query)]\n",
        "  query_vec = fasttext_matrix(query)[0]\n",
        "  result = {}\n",
        "\n",
        "  for i, document_vec in enumerate(ft_matrix):\n",
        "    sim = cos_sim(query_vec, document_vec)\n",
        "    result[sim] = index2doc[i]\n",
        "  final_result = sorted(result.items(), key=lambda x: x[0], reverse=True)[:100]\n",
        "  return final_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zoz0hLn_1fQd",
        "colab_type": "code",
        "outputId": "004d9e52-0c25-43ce-9c6d-6a21c520cf18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "%%time \n",
        "ft_search('в чем смысл жизни?', ft_matrix, f_model)[:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.21 s, sys: 14.1 ms, total: 1.22 s\n",
            "Wall time: 1.22 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.9999999999999999, 'в чем смысл этой жизни'),\n",
              " (0.899697839055339, 'в чем смысл или цель жизни'),\n",
              " (0.8958170229575113, 'истинный смысл жизни'),\n",
              " (0.8865399765234165, 'в чем смысл жизни только в одном слове'),\n",
              " (0.83917295080825, 'как мне найти смысл моей жизни')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcOyNIGtG4d9",
        "colab_type": "text"
      },
      "source": [
        "### Elmo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTXc8N2rG32g",
        "colab_type": "code",
        "outputId": "d8894697-7e45-4970-bcc8-25d1db839907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!wget 'http://vectors.nlpl.eu/repository/11/196.zip'\n",
        "!unzip '196.zip' -d 'elmo'"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-08 17:40:33--  http://vectors.nlpl.eu/repository/11/196.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206986345 (197M) [application/zip]\n",
            "Saving to: ‘196.zip’\n",
            "\n",
            "196.zip             100%[===================>] 197.40M  21.3MB/s    in 13s     \n",
            "\n",
            "2019-10-08 17:40:46 (15.1 MB/s) - ‘196.zip’ saved [206986345/206986345]\n",
            "\n",
            "Archive:  196.zip\n",
            "  inflating: elmo/meta.json          \n",
            "  inflating: elmo/model.hdf5         \n",
            "  inflating: elmo/options.json       \n",
            "  inflating: elmo/README             \n",
            "  inflating: elmo/vocab.txt          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccfp5I2XdXrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f573f312-1b1b-4dc2-e79f-f3a47457d277"
      },
      "source": [
        "!unzip 'simple_elmo.zip' "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  simple_elmo.zip\n",
            "  inflating: simple_elmo/.DS_Store   \n",
            "  inflating: simple_elmo/LICENSE     \n",
            "  inflating: simple_elmo/requirements.txt  \n",
            "  inflating: simple_elmo/bilm/elmo.py  \n",
            "  inflating: simple_elmo/bilm/__init__.py  \n",
            "  inflating: simple_elmo/bilm/__pycache__/model.cpython-36.pyc  \n",
            "  inflating: simple_elmo/bilm/__pycache__/elmo.cpython-36.pyc  \n",
            "  inflating: simple_elmo/bilm/__pycache__/data.cpython-37.pyc  \n",
            "  inflating: simple_elmo/bilm/__pycache__/data.cpython-36.pyc  \n",
            "  inflating: simple_elmo/bilm/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: simple_elmo/bilm/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: simple_elmo/bilm/model.py  \n",
            "  inflating: simple_elmo/bilm/data.py  \n",
            "  inflating: simple_elmo/elmo.ipynb  \n",
            "  inflating: simple_elmo/__pycache__/elmo_helpers.cpython-36.pyc  \n",
            "  inflating: simple_elmo/__pycache__/elmo_helpers.cpython-37.pyc  \n",
            "  inflating: simple_elmo/README      \n",
            "  inflating: simple_elmo/elmo/vocab.txt.gz  \n",
            "  inflating: simple_elmo/elmo/options.json  \n",
            "  inflating: simple_elmo/elmo/model.hdf5  \n",
            "  inflating: simple_elmo/elmo/vocab.txt  \n",
            "  inflating: simple_elmo/README.md   \n",
            "  inflating: simple_elmo/Pipfile     \n",
            "  inflating: simple_elmo/.gitignore  \n",
            "  inflating: simple_elmo/get_elmo_vectors.py  \n",
            "  inflating: simple_elmo/test.txt    \n",
            "  inflating: simple_elmo/.ipynb_checkpoints/elmo-checkpoint.ipynb  \n",
            "  inflating: simple_elmo/.git/ORIG_HEAD  \n",
            "  inflating: simple_elmo/.git/config  \n",
            "  inflating: simple_elmo/.git/objects/66/c027658892172346d1c2482b1332eb312974a0  \n",
            "  inflating: simple_elmo/.git/objects/68/32edc74076fb8c108ddb6adeb2deb3e48a2b75  \n",
            "  inflating: simple_elmo/.git/objects/0b/4ad6361aaf5b986314f714c6abe8e0ecfaf33d  \n",
            "  inflating: simple_elmo/.git/objects/93/5233fced53f8183acbe0f54f398dac14828eaf  \n",
            "  inflating: simple_elmo/.git/objects/94/715ae01fcea631b727013dc21b8f181d29779b  \n",
            "  inflating: simple_elmo/.git/objects/33/297c9f86854255d469c27b9a2a1268d718cb0a  \n",
            "  inflating: simple_elmo/.git/objects/33/0e1bed8d7cf9e94d18d31cb4e368f2f23a520a  \n",
            "  inflating: simple_elmo/.git/objects/ad/99e75b4db5d4a13056314b2cd3345aab459963  \n",
            "  inflating: simple_elmo/.git/objects/bb/d77505a4a92c9799e74c57dcf66dfafd8c4585  \n",
            "  inflating: simple_elmo/.git/objects/d8/a006c14c91cd5e1426e1373879a3edc1f220a2  \n",
            "  inflating: simple_elmo/.git/objects/ee/fd41b551d2b25358b3cd16aec7c01b3242513b  \n",
            "  inflating: simple_elmo/.git/objects/f2/88702d2fa16d3cdf0035b15a9fcbc552cd88e7  \n",
            "  inflating: simple_elmo/.git/objects/fb/856c0d332c42f0514c6f1eedb8219297a74d5d  \n",
            "  inflating: simple_elmo/.git/objects/ec/bf5948eaf945f685787aff03196332a7671fcc  \n",
            "  inflating: simple_elmo/.git/objects/ec/f401f73771a33262462d2d494b157e1137c749  \n",
            "  inflating: simple_elmo/.git/objects/18/197436d01c8276b6ee81b8ac755a42b3d6ad1a  \n",
            "  inflating: simple_elmo/.git/objects/89/4a44cc066a027465cd26d634948d56d13af9af  \n",
            "  inflating: simple_elmo/.git/objects/1a/cb12c1e6621fed10833c8d9fce4210fdd30681  \n",
            "  inflating: simple_elmo/.git/objects/75/3be45b66063756782683868ecde0ecbd2b204a  \n",
            "  inflating: simple_elmo/.git/objects/75/b5ebfc0df99e77fb9fb72ba34f44a19d74e7d4  \n",
            "  inflating: simple_elmo/.git/objects/86/7f131a290efb8a84e4a99f6d5a41b9160c5ff6  \n",
            "  inflating: simple_elmo/.git/objects/43/899a6e93fe16b00f22fb8ed39a0d3030286a18  \n",
            "  inflating: simple_elmo/.git/objects/00/0683b48cea0c4c8642db40e9d4ad0cc6d7371d  \n",
            "  inflating: simple_elmo/.git/objects/30/6c946676033045b0aa8816aa99f186d36c13bd  \n",
            "  inflating: simple_elmo/.git/objects/30/8b6fd48e0185b403e33278de8146c9f00339f8  \n",
            "  inflating: simple_elmo/.git/objects/30/4df8b82784251cf1e3f0f0b7eead9da371b57e  \n",
            "  inflating: simple_elmo/.git/objects/37/ca6f59c070ca5fb218e227db057e322b8c54b1  \n",
            "  inflating: simple_elmo/.git/objects/52/88949b94bd8dab3f9513ee211e0d62179a7947  \n",
            "  inflating: simple_elmo/.git/objects/af/0e4c1af3a04b924e7256a50f3b6a3fc590fc3a  \n",
            "  inflating: simple_elmo/.git/objects/de/50fb310b1709949b42bfd6ba7a67d73840b786  \n",
            "  inflating: simple_elmo/.git/objects/e6/a4e7c741ea87b98db530e93f443ca0966e6478  \n",
            "  inflating: simple_elmo/.git/objects/1c/f358f25c738e4f636c0bdc57922228e5b33760  \n",
            "  inflating: simple_elmo/.git/objects/47/67b9b8001c47699b2889aee231049ed9845854  \n",
            "  inflating: simple_elmo/.git/objects/13/9339d24958aa810fd500af406189144fd7ec43  \n",
            "  inflating: simple_elmo/.git/objects/25/5448830c19e99b8b7dda62dc5bf4c24b9e7879  \n",
            "  inflating: simple_elmo/.git/HEAD   \n",
            "  inflating: simple_elmo/.git/info/exclude  \n",
            "  inflating: simple_elmo/.git/logs/HEAD  \n",
            "  inflating: simple_elmo/.git/logs/refs/heads/master  \n",
            "  inflating: simple_elmo/.git/logs/refs/remotes/origin/HEAD  \n",
            "  inflating: simple_elmo/.git/logs/refs/stash  \n",
            "  inflating: simple_elmo/.git/description  \n",
            "  inflating: simple_elmo/.git/hooks/commit-msg.sample  \n",
            "  inflating: simple_elmo/.git/hooks/pre-rebase.sample  \n",
            "  inflating: simple_elmo/.git/hooks/pre-commit.sample  \n",
            "  inflating: simple_elmo/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: simple_elmo/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: simple_elmo/.git/hooks/pre-receive.sample  \n",
            "  inflating: simple_elmo/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: simple_elmo/.git/hooks/post-update.sample  \n",
            "  inflating: simple_elmo/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: simple_elmo/.git/hooks/pre-push.sample  \n",
            "  inflating: simple_elmo/.git/hooks/update.sample  \n",
            "  inflating: simple_elmo/.git/refs/heads/master  \n",
            "  inflating: simple_elmo/.git/refs/remotes/origin/HEAD  \n",
            "  inflating: simple_elmo/.git/refs/stash  \n",
            "  inflating: simple_elmo/.git/index  \n",
            "  inflating: simple_elmo/.git/packed-refs  \n",
            "  inflating: simple_elmo/vocabulary.py  \n",
            "  inflating: simple_elmo/Pipfile.lock  \n",
            "  inflating: simple_elmo/elmo_helpers.py  \n",
            "  inflating: simple_elmo/meta.json   \n",
            "  inflating: simple_elmo/.idea/vcs.xml  \n",
            "  inflating: simple_elmo/.idea/simple_elmo.iml  \n",
            "  inflating: simple_elmo/.idea/workspace.xml  \n",
            "  inflating: simple_elmo/.idea/modules.xml  \n",
            "  inflating: simple_elmo/.idea/misc.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFpwKp8He0_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "os.chdir('/content/simple_elmo/')\n",
        "from elmo_helpers import tokenize, get_elmo_vectors, load_elmo_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4moAk5a6fdaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "0c692bd7-4fd8-4e8b-d566-87ee58611a0f"
      },
      "source": [
        "batcher, sentence_character_ids, elmo_sentence_input = load_elmo_embeddings(os.getcwd()+'/elmo/')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/simple_elmo/elmo_helpers.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/simple_elmo/bilm/model.py:378: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/simple_elmo/bilm/model.py:522: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/simple_elmo/bilm/model.py:566: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/simple_elmo/bilm/model.py:567: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4vdawqrf1SO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08ef6c06-4203-4192-954c-6e464960e95b"
      },
      "source": [
        "%%time \n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  done = []\n",
        "  for i in range(150, len(docs_processed)+1, 150):\n",
        "    v_elmo = get_elmo_vectors(sess, docs_processed[i-150:i], batcher, \n",
        "                              sentence_character_ids, elmo_sentence_input)\n",
        "    for v in v_elmo:\n",
        "      done.append(np.mean(v[:len(docs_processed[i]), :], axis=0))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n",
            "Sentences in this batch: 150\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 44s, sys: 34.6 s, total: 3min 18s\n",
            "Wall time: 5min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7zXma8tcxeM",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 1__:    \n",
        "Сравните время индексации корпуса для каждой модели "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH4P6K76xEK5",
        "colab_type": "code",
        "outputId": "3a921e5e-c136-4a4d-a804-10e40b1dca40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "%%time\n",
        "ft_matrix = fasttext_matrix(docs_processed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.98 s, sys: 119 ms, total: 7.1 s\n",
            "Wall time: 7.11 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAUlcgRjlPPO",
        "colab_type": "text"
      },
      "source": [
        "Фасттекс индексируется намного быстрее, но это из-за недостатка мощности и оперативной памяти для elmo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2PIhjKzcxeN",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 2__:    \n",
        "Выведите качество поиска для каждой модели +  BM25 для сравнения\n",
        "\n",
        "Качество оцениваем так же, как в прошлом задании:\n",
        "    - если в топ-5 результатов выдачи попал хоть один релевантный документ, выдача точная\n",
        "    - если в топ-5 нет ни одного релеватного документа, выдача получает 0\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN2gKj4jcxeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}