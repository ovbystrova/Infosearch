{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "HW_Seminar2_BM25.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pjANy5SP5gTQ"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sofBcfk8RoiX",
        "colab_type": "text"
      },
      "source": [
        "## Лекция 2  BM5    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWLo2CFORoiZ",
        "colab_type": "text"
      },
      "source": [
        "## Функция ранжирования bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q-DpLDERoim",
        "colab_type": "text"
      },
      "source": [
        "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
        "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
        "\n",
        "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,D)*(k+1)}{TF(q_i,D)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
        "где   \n",
        ">$TF(q_i,D)$ - частота слова $q_i$ в документе $D$      \n",
        "$l(d)$ - длина документа (количество слов в нём)   \n",
        "*avgdl* — средняя длина документа в коллекции    \n",
        "$k$ и $b$ — свободные коэффициенты, обычно их выбирают как $k$=2.0 и $b$=0.75   \n",
        "$$$$\n",
        "$\\text{IDF}(q_i)$ - это модернизированная версия IDF: \n",
        "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
        ">> где $N$ - общее количество документов в коллекции   \n",
        "$n(q_i)$ — количество документов, содержащих $q_i$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V74tqk56m8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSdXMIRZ6cjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import pymorphy2 as pm\n",
        "import string\n",
        "import re\n",
        "\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2BBaCcL5-90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(file):\n",
        "  '''Функция из файла делает списки запросов'''\n",
        "  with open(file, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader, None)\n",
        "        documents_1 = []\n",
        "        documents_2 = []\n",
        "        data = []\n",
        "        for row in reader:\n",
        "          documents_1.append(row[1])\n",
        "          documents_2.append(row[2])\n",
        "          data.append([int(row[0])])\n",
        "            \n",
        "  return data[:1000], documents_1[:1000], documents_2[:1000]\n",
        "\n",
        "data, documents_1, documents_2= get_data('quora_question_pairs_rus.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD0dKdXB6gTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import nltk\n",
        "#nltk.download('stopwords')\n",
        "stopWords = list(stopwords.words('russian'))\n",
        "morph = pm.MorphAnalyzer()\n",
        "\n",
        "def preprocess(text : list) -> list:\n",
        "    \"\"\"Функция на вход получает текст и возвращает список нормализованных слов, без знаков пунктуации, без стопслов\"\"\"\n",
        "    text = text.lower()\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    filtered_words = list(filter(lambda token: token not in stopwords.words('russian'), tokens))\n",
        "    norm_words = [morph.parse(token)[0].normal_form for token in filtered_words]\n",
        "    return norm_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30kBAzlA6Wjk",
        "colab_type": "code",
        "outputId": "1fa5e4ef-5d8e-4d74-ca3b-2dfe2ba1c3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "def avg_length(documents : list) -> float:\n",
        "  '''Считает среднюю длину документа в коллекции в словах'''  \n",
        "  avg_length = sum(np.array([len(document.split()) for document in documents])) / len(documents)\n",
        "  return float(avg_length)\n",
        "print(avg_length(documents_1), avg_length(documents_2))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.22558 9.42693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzjWCsPC8I9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) Dictionary doc : index and reverse index : doc\n",
        "# 2) Dictionary index_doc : len(doc) \n",
        "index2doc = dict(enumerate(documents_1))\n",
        "doc2index = {value : key for key, value in index2doc.items()}\n",
        "doc2len = {key : len(value.split()) for key, value in index2doc.items()}\n",
        "#index2doc, doc2index, doc2len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZC8yQnl_R8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Теперь сделаем predprocess всех текстов и создадим словарь idx2norm_doc\n",
        "docs_processed = [preprocess(document) for document in documents_1]\n",
        "idx2doc_n = dict(enumerate(docs_processed))\n",
        "#idx2doc_n\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gROTtgW26axy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = len(documents_1)\n",
        "avg_length = avg_length(documents_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSMmRHuH6ys3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from collections import defaultdict\n",
        "#Считаем TF \n",
        "def reverse_indx(idx2doc_n : dict):\n",
        "    \"\"\"\n",
        "    Функция на вход получает индексированный словарь, на выход - обратный индекс\n",
        "    Где для каждого токена есть словарь вида index_doc : tf\n",
        "    \"\"\"\n",
        "    #ind_doc2tf = defaultdict(lambda: int())\n",
        "    ind_doc2tf={}\n",
        "    for key, value in idx2doc_n.items():\n",
        "        for item in value:\n",
        "            tf = value.count(item)\n",
        "            if item not in ind_doc2tf.keys():\n",
        "                #reverse_index_dict[item] = {tf : key}\n",
        "                ind_doc2tf[item] = {key:tf}\n",
        "            else:\n",
        "                #reverse_index_dict[item][tf] = key\n",
        "                ind_doc2tf[item][key]  = tf\n",
        "    return ind_doc2tf\n",
        "\n",
        "reverse_d = reverse_indx(idx2doc_n)\n",
        "#reverse_d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ZlnC3g-mg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Сколько докумментов содержат слово. \n",
        "#word2count_doc = defaultdict(lambda: int())\n",
        "word2count_doc = {key : len(value.keys()) for key, value in reverse_d.items()}\n",
        "#word2count_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMIdvyqe5lco",
        "colab": {}
      },
      "source": [
        "### реализуйте эту функцию ранжирования \n",
        "from math import log\n",
        "\n",
        "def bm25(document, query, k=2.0, b=0.75,\n",
        "         N=N, avg_length=avg_length, reverse_d=reverse_d, \n",
        "         index2doc=index2doc, doc2index=doc2index, word2count_doc=word2count_doc) -> float:\n",
        "    '''Функция ранжирования bm25 для одного запроса для документа'''\n",
        "        \n",
        "    try:\n",
        "      doc_id = doc2index[document] \n",
        "    except:\n",
        "      return 0.0\n",
        "    #document_processed = preprocess(document)\n",
        "    document_processed = idx2doc_n[doc_id]\n",
        "    query = preprocess(query)\n",
        "    #print(document_processed, query)\n",
        "  \n",
        "    \n",
        "    bm_total = 0\n",
        "    for word in query:\n",
        "      \n",
        "      tf  = reverse_d.get(word,{-1:0}).get(doc_id,0)\n",
        "      #print(tf)\n",
        "      count_docs= word2count_doc.get(word, 0)\n",
        "      #print(count_docs)\n",
        "      \n",
        "      idf = log((N-count_docs +0.5)/(count_docs + 0.5))\n",
        "      bm = idf * (tf * (k+1) / (tf + k * (1-b+b*(len(document_processed)/avg_length))))\n",
        "      bm_total += bm\n",
        "    \n",
        "    return bm_total "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M_O64m9u5ilL"
      },
      "source": [
        "### __Задача 1__:    \n",
        "Напишите два поисковика на *BM25*. Один через подсчет метрики по формуле для каждой пары слово-документ, второй через умножение матрицы на вектор. \n",
        "\n",
        "Сравните время работы поиска на 100к запросах. В качестве корпуса возьмем \n",
        "[Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SciCAZssLCWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXDAO4XAltZn",
        "colab_type": "code",
        "outputId": "26408817-f243-4e48-f9e5-bde83b08016d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(documents_2), len(documents_1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgBhL9q-Gq9Z",
        "colab_type": "code",
        "outputId": "33f568cc-affb-4442-87e2-39dbace48c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Первый вариант, считаем метрику по формуле для каждой пары слово документ. \n",
        "#Пусть запрос - это documents_2, а документ - documents_1\n",
        "%%time\n",
        "for i, query in enumerate(documents_2[:1000]):  \n",
        "  if i % 10 == 0:\n",
        "    print(i // 10, 'out of', 100)\n",
        "  bms = [(0,0)]\n",
        "  for document in documents_1[:1000]:\n",
        "    bm = bm25(document, query)        \n",
        "    if bm > bms[0][0]:\n",
        "      bms.insert(0, (bm, document))\n",
        "\n",
        "  for bm in bms[:10]:\n",
        "    pass\n",
        "    #print(dict_bm25[bm] + ':' + str(bm))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 out of 100\n",
            "1 out of 100\n",
            "2 out of 100\n",
            "3 out of 100\n",
            "4 out of 100\n",
            "5 out of 100\n",
            "6 out of 100\n",
            "7 out of 100\n",
            "8 out of 100\n",
            "9 out of 100\n",
            "10 out of 100\n",
            "11 out of 100\n",
            "12 out of 100\n",
            "13 out of 100\n",
            "14 out of 100\n",
            "15 out of 100\n",
            "16 out of 100\n",
            "17 out of 100\n",
            "18 out of 100\n",
            "19 out of 100\n",
            "20 out of 100\n",
            "21 out of 100\n",
            "22 out of 100\n",
            "23 out of 100\n",
            "24 out of 100\n",
            "25 out of 100\n",
            "26 out of 100\n",
            "27 out of 100\n",
            "28 out of 100\n",
            "29 out of 100\n",
            "30 out of 100\n",
            "31 out of 100\n",
            "32 out of 100\n",
            "33 out of 100\n",
            "34 out of 100\n",
            "35 out of 100\n",
            "36 out of 100\n",
            "37 out of 100\n",
            "38 out of 100\n",
            "39 out of 100\n",
            "40 out of 100\n",
            "41 out of 100\n",
            "42 out of 100\n",
            "43 out of 100\n",
            "44 out of 100\n",
            "45 out of 100\n",
            "46 out of 100\n",
            "47 out of 100\n",
            "48 out of 100\n",
            "49 out of 100\n",
            "50 out of 100\n",
            "51 out of 100\n",
            "52 out of 100\n",
            "53 out of 100\n",
            "54 out of 100\n",
            "55 out of 100\n",
            "56 out of 100\n",
            "57 out of 100\n",
            "58 out of 100\n",
            "59 out of 100\n",
            "60 out of 100\n",
            "61 out of 100\n",
            "62 out of 100\n",
            "63 out of 100\n",
            "64 out of 100\n",
            "65 out of 100\n",
            "66 out of 100\n",
            "67 out of 100\n",
            "68 out of 100\n",
            "69 out of 100\n",
            "70 out of 100\n",
            "71 out of 100\n",
            "72 out of 100\n",
            "73 out of 100\n",
            "74 out of 100\n",
            "75 out of 100\n",
            "76 out of 100\n",
            "77 out of 100\n",
            "78 out of 100\n",
            "79 out of 100\n",
            "80 out of 100\n",
            "81 out of 100\n",
            "82 out of 100\n",
            "83 out of 100\n",
            "84 out of 100\n",
            "85 out of 100\n",
            "86 out of 100\n",
            "87 out of 100\n",
            "88 out of 100\n",
            "89 out of 100\n",
            "90 out of 100\n",
            "91 out of 100\n",
            "92 out of 100\n",
            "93 out of 100\n",
            "94 out of 100\n",
            "95 out of 100\n",
            "96 out of 100\n",
            "97 out of 100\n",
            "98 out of 100\n",
            "99 out of 100\n",
            "CPU times: user 34min 13s, sys: 2min 11s, total: 36min 25s\n",
            "Wall time: 36min 30s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkf_trbWr-D7",
        "colab_type": "text"
      },
      "source": [
        "Поиск выполняется за 22.8 секунды для 100 запросов. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pjANy5SP5gTQ"
      },
      "source": [
        "### __Задача 2__:    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wN_WccpE5f10"
      },
      "source": [
        "Выведите 10 первых результатов и их близость по метрике BM25 по запросу **рождественские каникулы** на нашем корпусе  Quora question pairs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQYjNvfC-v_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(file):\n",
        "  '''Функция из файла делает списки запросов'''\n",
        "  with open(file, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader, None)\n",
        "        documents_1 = []\n",
        "        documents_2 = []\n",
        "        data = []\n",
        "        for row in reader:\n",
        "          documents_1.append(row[1])\n",
        "          documents_2.append(row[2])\n",
        "          data.append([int(row[0])])\n",
        "            \n",
        "  return data[:100000], documents_1[:100000], documents_2[:100000]\n",
        "\n",
        "data, documents_1, documents_2= get_data('quora_question_pairs_rus.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4KZsz5xBXso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "eb1a8bf4-cf95-4587-aa7a-30b8ffc2e7bb"
      },
      "source": [
        "print(len(list(index2doc.keys())))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCg1hJ6N5LFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ef22a8a2-7092-42e1-ca46-25df30b07204"
      },
      "source": [
        "bms = [(0,0)]\n",
        "query = 'рождественские каникулы'\n",
        "for document in documents_1:\n",
        "  bm = bm25(document, query)\n",
        "  if bm > bms[0][0]:\n",
        "    bms.insert(0, (bm, document))\n",
        "print(bms[:10])\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(14.998482869694746, 'какие рождественские традиции вы и ваша семья имеете на рождественский вечер и рождественский день'), (13.97776761709508, 'как вы проводите летние каникулы'), (12.892298236264834, 'какой лучший рождественский подарок для вас'), (9.920497087715205, 'которые являются лучшими местами для посещения в гоа во время каникул'), (9.714033240803387, 'что в вашем рождественском списке в этом году, на что вы надеетесь, анта принесет вам'), (9.376179865014187, 'что лучше всего безопасное место для 2 - 3-дневных каникул с моим gf в сентябре'), (0, 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FlhRgowN5fcV"
      },
      "source": [
        "### __Задача 3__:    \n",
        "\n",
        "Посчитайте точность поиска при \n",
        "1. BM25, b=0.75 \n",
        "2. BM15, b=0 \n",
        "3. BM11, b=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8gRIRgJ6THS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7c285e9a-d821-44b5-f195-f2c3fcb4fd31"
      },
      "source": [
        "bms = [(0,0)]\n",
        "metric = 0\n",
        "query = 'рождественские каникулы'\n",
        "for document in documents_1[:1000]:\n",
        "  bm = bm25(document, query, b=0.75)\n",
        "  if bm > bms[0][0]:\n",
        "    bms.insert(0, (bm, document))\n",
        "  d_set = set(preprocess(document))\n",
        "  q_set = set(preprocess(query))\n",
        "  metric += len(d_set & q_set) / len(d_set | q_set)\n",
        "metric\n",
        "print(metric)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Silnn-7o6p61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bms = [(0,0)]\n",
        "metric = 0\n",
        "query = 'рождественские каникулы'\n",
        "for document in documents_1:\n",
        "  bm = bm25(document, query, b=0)\n",
        "  if bm > bms[0][0]:\n",
        "    bms.insert(0, (bm, document))\n",
        "  d_set = set(preprocess(document))\n",
        "  q_set = set(preprocess(query))\n",
        "  metric += len(d_set & q_set) / len(d_set | q_set)\n",
        "  metric = metric / 5\n",
        "print(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y15493K080GK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bms = [(0,0)]\n",
        "metric = 0\n",
        "query = 'рождественские каникулы'\n",
        "for document in documents_1:\n",
        "  bm = bm25(document, query, b=1)\n",
        "  if bm > bms[0][0]:\n",
        "    bms.insert(0, (bm, document))\n",
        "  d_set = set(preprocess(document))\n",
        "  q_set = set(preprocess(query))\n",
        "  metric += len(d_set & q_set) / len(d_set | q_set)\n",
        "  metric = metric / 5\n",
        "print(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}